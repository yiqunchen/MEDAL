## MEDAL Dataset

​MEDAL (Medical Evidence Discrepancy Assessment with LLMs) is a proposed dataset designed to evaluate the capabilities of Large Language Models (LLMs) in assessing the quality of medical evidence, particularly when discrepancies arise between observational studies and clinical trials. The primary objective is to determine how effectively LLMs can discern the most accurate conclusions when faced with contradictory research findings.​

### Key Components of the MEDAL Project:

*Dataset Compilation*:

- Curate a comprehensive collection of paired observational studies and clinical trials that report on similar medical interventions or outcomes but present differing conclusions.​
Ensure the dataset spans multiple clinical domains to assess the generalizability of LLMs across various medical topics.​
Annotation and Evaluation:

- Develop a standardized annotation schema to categorize the nature and extent of discrepancies between studies.​
Engage medical experts to provide ground truth assessments, determining which study's conclusions are more aligned with current clinical guidelines or consensus.​
LLM Assessment:

- Deploy state-of-the-art LLMs to analyze the dataset, prompting them to provide summaries, reconcile conflicting findings, and indicate which study they deem more credible.​
Evaluate the LLMs' outputs against expert assessments, focusing on accuracy, coherence, and the ability to handle contradictory information.
