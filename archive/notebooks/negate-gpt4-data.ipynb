{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "113be1e8-7944-4d5d-a36c-71eddd6ee785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import argparse\n",
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "from collections import defaultdict\n",
    "from urllib.error import HTTPError\n",
    "from urllib.parse import quote_plus\n",
    "from Bio import Entrez\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import tqdm\n",
    "import openai\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "from openai import OpenAI, AsyncOpenAI\n",
    "Entrez.api_key = \"***ENTREZ_API_KEY_REDACTED***\"\n",
    "api_key = \"OPENAI_API_KEY_REDACTED\"\n",
    "\n",
    "json_path = \"/Users/yiquntchen/Downloads/test-temp-4o-one-question-async.json\"  # Replace with desired output path\n",
    "with open(json_path, 'rb') as f:\n",
    "    converted_dict = json.load(f)\n",
    "    \n",
    "openai.api_key = api_key #os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8cfa4b83-2ef9-405b-b554-875ae9783a83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "88aac2f7-e411-4be8-83ae-e2fa0fe70251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: safer to store as environment variable\n",
    "\n",
    "# --- Functions from earlier ---\n",
    "def generate_negation_prompt(entry):\n",
    "    prompt = f\"\"\"\n",
    "You are a clinical research expert with comprehensive knowledge of systematic reviews, randomized controlled trials (RCTs), \n",
    "and observational studies. Your task is to negate specific fields in a medical evidence summary while preserving the integrity of \n",
    "the original data.\n",
    "\n",
    "Here is the medical evidence summary you need to analyze:\n",
    "{{\n",
    "  \"doi\": \"{entry['doi']}\",\n",
    "  \"question\": \"{entry['question']}\",\n",
    "  \"answer\": \"{entry['answer']}\",\n",
    "  \"evidence-quality\": \"{entry['evidence-quality']}\",\n",
    "  \"discrepancy\": \"{entry['discrepancy']}\",\n",
    "}}\n",
    "\n",
    "Your objective is to negate the 'question' and 'answer' fields in this summary according to the following rules:\n",
    "\n",
    "1. NEGATED_QUESTION:\n",
    "   - If the question is in the form \"if A improves B\", negate it to \"if A reduces B\". \n",
    "   - The negtation must be *logically correct*. That is, original question and answer needs to imply that the negated question and answer are correct.\n",
    "   - If the question is in another form, attempt to negate its core meaning using verb while keeping other parts of the question mostly the same.\n",
    "   - If negation is not clear or possible, use \"Not applicable\" as the NEGATED_QUESTION.\n",
    "\n",
    "2. NEGATED_ANSWER: \n",
    "   - If the NEGATED_QUESTION is \"Not applicable\", answer should be \"Not applicable\".\n",
    "   - If the answer is \"Yes\", change it to \"No\".\n",
    "   - If the answer is \"No\", change it to \"Yes\".\n",
    "   - If the answer is \"No Evidence\", leave it unchanged.\n",
    "\n",
    "All other fields, including the original 'question', 'discrepancy', and 'evidence-quality', must remain exactly the same.\n",
    "\n",
    "Provide the negated summary in the following JSON format:\n",
    "\n",
    "{{\n",
    "  \"doi\": \"[Original DOI]\",\n",
    "  \"question\": \"[NEGATED_QUESTION]\",\n",
    "  \"answer\": \"[NEGATED_ANSWER]\",\n",
    "  \"original_question\": [Original question],\n",
    "  \"original_answer\": [Original answer],\n",
    "  \"evidence-quality\": \"[Original evidence-quality]\",\n",
    "  \"discrepancy\": \"[Original discrepancy]\",\n",
    "}}\n",
    "\n",
    "Remember to replace the placeholders in square brackets with the appropriate content from the original summary or your negated versions.\n",
    "\"\"\"\n",
    "    return prompt.strip()\n",
    "\n",
    "def check_negation_validity(original_answer, negated_answer):\n",
    "    if original_answer == \"Yes\" and negated_answer == \"No\":\n",
    "        return True\n",
    "    elif original_answer == \"No\" and negated_answer == \"Yes\":\n",
    "        return True\n",
    "    elif original_answer == \"No Evidence\" and negated_answer == \"No Evidence\":\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def process_llm_response(original_entry, llm_response_dict):\n",
    "    original_answer = original_entry[\"answer\"]\n",
    "    negated_answer = llm_response_dict[\"answer\"]\n",
    "    valid = check_negation_validity(original_answer, negated_answer)\n",
    "    llm_response_dict[\"negation-valid\"] = valid\n",
    "    return llm_response_dict\n",
    "\n",
    "# --- Call OpenAI for each prompt ---\n",
    "def call_openai_with_prompt(prompt, model, client, max_retries=3):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            completion = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "            temperature=0,\n",
    "        )\n",
    "            raw_content = completion.choices[0].message.content.strip()\n",
    "            return json.loads(raw_content)\n",
    "            # return completion.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt+1} failed: {e}\")\n",
    "            time.sleep(2 ** attempt)\n",
    "    raise RuntimeError(\"OpenAI API failed after several retries.\")\n",
    "\n",
    "# --- Final driver function ---\n",
    "def generate_llm_responses_and_validate(converted_dict, model):\n",
    "    llm_responses = {}\n",
    "    final_dataset = []\n",
    "    invalid_cases = []\n",
    "    client = OpenAI(api_key=api_key)\n",
    "\n",
    "    for key, entry in tqdm.tqdm(converted_dict.items()):\n",
    "        prompt = generate_negation_prompt(entry)\n",
    "        try:\n",
    "            llm_response = call_openai_with_prompt(prompt, model, client)\n",
    "            processed = process_llm_response(entry, llm_response)\n",
    "            llm_responses[key] = processed\n",
    "            final_dataset.append(processed)\n",
    "            if not processed[\"negation-valid\"]:\n",
    "                invalid_cases.append(processed)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process key {key}: {e}\")\n",
    "\n",
    "    return final_dataset, invalid_cases, llm_responses\n",
    "\n",
    "# sampled_data = dict(random.sample(list(converted_dict.items()), 5))\n",
    "final_dataset, invalid_cases, llm_responses = generate_llm_responses_and_validate(converted_dict, 'gpt-4o-mini')\n",
    "\n",
    "# Optional: Save results\n",
    "with open(\"/Users/yiquntchen/Downloads/test-4o-one-negated-dataset.jsonl\", \"w\") as f:\n",
    "    for item in final_dataset:\n",
    "        f.write(json.dumps(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a69dc1-baaa-4cf1-8d78-d5f5f6217004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e7660793-4284-4504-b363-e0a4876f30c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json_path = \"/Users/yiquntchen/Downloads/test-4o-one-negated-dataset.jsonl\"\n",
    "\n",
    "negated_data = []\n",
    "with open(json_path, 'r') as f:  # Use 'r' instead of 'rb'\n",
    "    for line in f:\n",
    "        negated_data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ed41c4-7d39-4e10-ac39-73f5feab7236",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
