{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac9002a8-3b73-4e38-9238-7ca552984479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ac9529d-3baf-488b-b812-cb3091260967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class CochraneEffectSizeExtractor:\n",
    "    \"\"\"Extract effect sizes from Cochrane Library systematic reviews.\"\"\"\n",
    "    \n",
    "    def __init__(self, output_dir=\"cochrane_data\"):\n",
    "        self.base_url = \"https://www.cochranelibrary.com\"\n",
    "        self.search_url = f\"{self.base_url}/advanced-search\"\n",
    "        self.headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\"\n",
    "        }\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.output_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Set up Selenium\n",
    "        self.setup_selenium()\n",
    "        \n",
    "    def setup_selenium(self):\n",
    "        \"\"\"Set up Selenium webdriver for handling dynamic content.\"\"\"\n",
    "        options = Options()\n",
    "        options.add_argument(\"--headless\")  # Run in headless mode\n",
    "        options.add_argument(\"--no-sandbox\")\n",
    "        options.add_argument(\"--disable-dev-shm-usage\")\n",
    "        self.driver = webdriver.Chrome(options=options)\n",
    "        \n",
    "    def search_reviews(self, query, page=1, per_page=25):\n",
    "        \"\"\"\n",
    "        Search Cochrane Library for reviews matching query.\n",
    "        \n",
    "        Args:\n",
    "            query: Search query string\n",
    "            page: Page number\n",
    "            per_page: Results per page\n",
    "            \n",
    "        Returns:\n",
    "            List of review URLs\n",
    "        \"\"\"\n",
    "        params = {\n",
    "            \"searchBy\": \"1\",\n",
    "            \"searchText\": query,\n",
    "            \"searchType\": \"basic\",\n",
    "            \"facetMode\": \"reset\",\n",
    "            \"facetTab\": \"reviews\",\n",
    "            \"facetToken\": \"\",\n",
    "            \"page\": page,\n",
    "            \"pageSize\": per_page,\n",
    "            \"sortBy\": \"relevancy\"\n",
    "        }\n",
    "        \n",
    "        logger.info(f\"Searching Cochrane Library for: {query}\")\n",
    "        response = requests.get(self.search_url, params=params, headers=self.headers)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            logger.error(f\"Search failed with status code: {response.status_code}\")\n",
    "            return []\n",
    "            \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        review_links = []\n",
    "        \n",
    "        # Extract links to reviews\n",
    "        for result in soup.select(\".search-results-item-body\"):\n",
    "            title_element = result.select_one(\".result-title\")\n",
    "            if title_element and title_element.has_attr('href'):\n",
    "                review_links.append(f\"{self.base_url}{title_element['href']}\")\n",
    "                \n",
    "        logger.info(f\"Found {len(review_links)} reviews\")\n",
    "        return review_links\n",
    "        \n",
    "    def extract_effect_sizes_from_page(self, url):\n",
    "        \"\"\"\n",
    "        Extract effect sizes from a Cochrane review page.\n",
    "        \n",
    "        Args:\n",
    "            url: URL of the Cochrane review\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing effect size data\n",
    "        \"\"\"\n",
    "        logger.info(f\"Extracting effect sizes from: {url}\")\n",
    "        \n",
    "        # Use Selenium to load the page (handles JavaScript)\n",
    "        self.driver.get(url)\n",
    "        \n",
    "        # Wait for content to load\n",
    "        WebDriverWait(self.driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \".publication-content\"))\n",
    "        )\n",
    "        \n",
    "        # Get page source after JavaScript execution\n",
    "        html = self.driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        # Extract review metadata\n",
    "        title = soup.select_one(\"h1.publication-title\")\n",
    "        title_text = title.text.strip() if title else \"Unknown Title\"\n",
    "        \n",
    "        # Extract DOI\n",
    "        doi_element = soup.select_one(\".publication-doi\")\n",
    "        doi = doi_element.text.strip() if doi_element else None\n",
    "        \n",
    "        # Find forest plots (usually contain effect sizes)\n",
    "        figures = soup.select(\"figure.figure\")\n",
    "        \n",
    "        results = {\n",
    "            \"title\": title_text,\n",
    "            \"url\": url,\n",
    "            \"doi\": doi,\n",
    "            \"effect_sizes\": []\n",
    "        }\n",
    "        \n",
    "        # Process tables (often contain effect sizes)\n",
    "        tables = soup.select(\"table.table\")\n",
    "        for i, table in enumerate(tables):\n",
    "            table_data = self._extract_data_from_table(table)\n",
    "            if table_data:\n",
    "                results[\"effect_sizes\"].extend(table_data)\n",
    "        \n",
    "        # Try to find effect sizes in text\n",
    "        effect_sizes_in_text = self._extract_effect_sizes_from_text(soup)\n",
    "        if effect_sizes_in_text:\n",
    "            results[\"effect_sizes\"].extend(effect_sizes_in_text)\n",
    "            \n",
    "        logger.info(f\"Extracted {len(results['effect_sizes'])} effect size entries\")\n",
    "        return results\n",
    "        \n",
    "    def _extract_data_from_table(self, table):\n",
    "        \"\"\"Extract effect size data from a table element.\"\"\"\n",
    "        effect_sizes = []\n",
    "        \n",
    "        # Check if this table likely contains effect sizes\n",
    "        headers = [th.text.strip().lower() for th in table.select(\"th\")]\n",
    "        \n",
    "        effect_size_indicators = [\n",
    "            \"effect\", \"risk ratio\", \"odds ratio\", \"hazard ratio\", \n",
    "            \"mean difference\", \"std. mean difference\", \"rate ratio\",\n",
    "            \"rr\", \"or\", \"hr\", \"md\", \"smd\", \"ci\", \"confidence\"\n",
    "        ]\n",
    "        \n",
    "        if not any(indicator in \" \".join(headers).lower() for indicator in effect_size_indicators):\n",
    "            return []\n",
    "            \n",
    "        # Process table rows\n",
    "        rows = table.select(\"tr\")\n",
    "        if len(rows) <= 1:  # Skip tables with just headers\n",
    "            return []\n",
    "            \n",
    "        # Extract column indices for relevant data\n",
    "        col_indices = {}\n",
    "        for i, header in enumerate(headers):\n",
    "            for term, pattern in [\n",
    "                (\"intervention\", r\"interven|treatment|therapy|drug|comparison\"),\n",
    "                (\"outcome\", r\"outcome|endpoint|measure\"),\n",
    "                (\"effect_size\", r\"effect|estimate|ratio|difference|rr|or|hr|md|smd\"),\n",
    "                (\"ci_lower\", r\"lower|95%.*lower|ci.*lower\"),\n",
    "                (\"ci_upper\", r\"upper|95%.*upper|ci.*upper\"),\n",
    "                (\"p_value\", r\"p.*value|p\\b\"),\n",
    "                (\"measure_type\", r\"measure|type|statistic\")\n",
    "            ]:\n",
    "                if re.search(pattern, header, re.IGNORECASE):\n",
    "                    col_indices[term] = i\n",
    "                    \n",
    "        # Process data rows\n",
    "        for row in rows[1:]:  # Skip header row\n",
    "            cells = row.select(\"td\")\n",
    "            if len(cells) < len(headers):\n",
    "                continue\n",
    "                \n",
    "            # Extract data from cells based on identified columns\n",
    "            effect_size_data = {\n",
    "                \"intervention\": self._get_cell_content(cells, col_indices.get(\"intervention\")),\n",
    "                \"outcome\": self._get_cell_content(cells, col_indices.get(\"outcome\")),\n",
    "                \"effect_size\": self._get_cell_content(cells, col_indices.get(\"effect_size\")),\n",
    "                \"ci_lower\": self._get_cell_content(cells, col_indices.get(\"ci_lower\")),\n",
    "                \"ci_upper\": self._get_cell_content(cells, col_indices.get(\"ci_upper\")),\n",
    "                \"p_value\": self._get_cell_content(cells, col_indices.get(\"p_value\")),\n",
    "                \"measure_type\": self._get_cell_content(cells, col_indices.get(\"measure_type\")),\n",
    "                \"source\": \"table\"\n",
    "            }\n",
    "            \n",
    "            # Clean and normalize numeric values\n",
    "            for field in [\"effect_size\", \"ci_lower\", \"ci_upper\", \"p_value\"]:\n",
    "                if effect_size_data[field]:\n",
    "                    effect_size_data[field] = self._normalize_numeric(effect_size_data[field])\n",
    "                    \n",
    "            # Infer measure type if missing\n",
    "            if not effect_size_data[\"measure_type\"] and effect_size_data[\"effect_size\"]:\n",
    "                measure_type = None\n",
    "                for header in headers:\n",
    "                    if \"odds ratio\" in header.lower() or \"or\" == header.lower():\n",
    "                        measure_type = \"Odds Ratio\"\n",
    "                    elif \"risk ratio\" in header.lower() or \"rr\" == header.lower():\n",
    "                        measure_type = \"Risk Ratio\"\n",
    "                    elif \"hazard ratio\" in header.lower() or \"hr\" == header.lower():\n",
    "                        measure_type = \"Hazard Ratio\"\n",
    "                    elif \"mean difference\" in header.lower() or \"md\" == header.lower():\n",
    "                        measure_type = \"Mean Difference\"\n",
    "                    elif \"std\" in header.lower() and \"mean difference\" in header.lower() or \"smd\" == header.lower():\n",
    "                        measure_type = \"Standardized Mean Difference\"\n",
    "                        \n",
    "                effect_size_data[\"measure_type\"] = measure_type\n",
    "                \n",
    "            # Add to collection if we have actual effect size data\n",
    "            if effect_size_data[\"effect_size\"]:\n",
    "                effect_sizes.append(effect_size_data)\n",
    "                \n",
    "        return effect_sizes\n",
    "    \n",
    "    def _get_cell_content(self, cells, idx):\n",
    "        \"\"\"Extract text content from a table cell safely.\"\"\"\n",
    "        if idx is not None and idx < len(cells):\n",
    "            return cells[idx].text.strip()\n",
    "        return None\n",
    "        \n",
    "    def _normalize_numeric(self, value):\n",
    "        \"\"\"Clean and normalize numeric values from text.\"\"\"\n",
    "        if not value:\n",
    "            return value\n",
    "            \n",
    "        # Remove common non-numeric characters\n",
    "        value = re.sub(r'[^\\d\\.\\-\\+]', '', value)\n",
    "        \n",
    "        try:\n",
    "            return float(value)\n",
    "        except ValueError:\n",
    "            return value\n",
    "            \n",
    "    def _extract_effect_sizes_from_text(self, soup):\n",
    "        \"\"\"Extract effect sizes mentioned in the text content.\"\"\"\n",
    "        effect_sizes = []\n",
    "        content_sections = soup.select(\".publication-content p\")\n",
    "        \n",
    "        # Patterns to identify effect sizes in text\n",
    "        patterns = [\n",
    "            # Risk Ratio/Odds Ratio pattern: RR 1.23 (95% CI 1.11 to 1.35)\n",
    "            r'(Risk Ratio|Odds Ratio|Hazard Ratio|Rate Ratio|RR|OR|HR)\\s*(=|:)?\\s*(\\d+\\.\\d+)\\s*\\(95%\\s*CI\\s*(\\d+\\.\\d+)\\s*to\\s*(\\d+\\.\\d+)\\)',\n",
    "            \n",
    "            # Mean Difference pattern: MD -2.30 (95% CI -4.11 to -0.49)\n",
    "            r'(Mean Difference|Std\\. Mean Difference|Standardized Mean Difference|MD|SMD)\\s*(=|:)?\\s*([\\-\\+]?\\d+\\.\\d+)\\s*\\(95%\\s*CI\\s*([\\-\\+]?\\d+\\.\\d+)\\s*to\\s*([\\-\\+]?\\d+\\.\\d+)\\)',\n",
    "            \n",
    "            # P-value pattern: P = 0.002\n",
    "            r'P\\s*(=|:)\\s*(\\d+\\.\\d+)'\n",
    "        ]\n",
    "        \n",
    "        for section in content_sections:\n",
    "            text = section.text\n",
    "            \n",
    "            # Extract outcome context\n",
    "            outcome_match = re.search(r'for\\s+([^\\.]+)', text)\n",
    "            outcome = outcome_match.group(1).strip() if outcome_match else None\n",
    "            \n",
    "            # Extract intervention context\n",
    "            intervention_match = re.search(r'(compared|versus|vs\\.?)\\s+([^\\.]+)', text, re.IGNORECASE)\n",
    "            intervention = intervention_match.group(2).strip() if intervention_match else None\n",
    "            \n",
    "            # Look for effect size patterns\n",
    "            for pattern in patterns:\n",
    "                matches = re.finditer(pattern, text)\n",
    "                for match in matches:\n",
    "                    groups = match.groups()\n",
    "                    \n",
    "                    if len(groups) >= 3:  # Full effect size with CI\n",
    "                        effect_size_data = {\n",
    "                            \"intervention\": intervention,\n",
    "                            \"outcome\": outcome,\n",
    "                            \"measure_type\": groups[0],\n",
    "                            \"effect_size\": float(groups[2]),\n",
    "                            \"source\": \"text\"\n",
    "                        }\n",
    "                        \n",
    "                        if len(groups) >= 5:  # Has confidence interval\n",
    "                            effect_size_data[\"ci_lower\"] = float(groups[3])\n",
    "                            effect_size_data[\"ci_upper\"] = float(groups[4])\n",
    "                            \n",
    "                        effect_sizes.append(effect_size_data)\n",
    "                    \n",
    "        return effect_sizes\n",
    "    \n",
    "    def extract_effect_sizes_for_topic(self, topic, max_reviews=10):\n",
    "        \"\"\"\n",
    "        Extract effect sizes for a specific medical topic.\n",
    "        \n",
    "        Args:\n",
    "            topic: Medical topic or condition\n",
    "            max_reviews: Maximum number of reviews to process\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with extracted effect sizes\n",
    "        \"\"\"\n",
    "        # Search for reviews containing the topic and likely to have effect sizes\n",
    "        query = f'\"{topic}\" AND (\"meta-analysis\" OR \"effect size\" OR \"forest plot\")'\n",
    "        review_links = self.search_reviews(query)\n",
    "        \n",
    "        all_effect_sizes = []\n",
    "        \n",
    "        # Process each review up to the maximum\n",
    "        for i, link in enumerate(review_links[:max_reviews]):\n",
    "            logger.info(f\"Processing review {i+1}/{min(len(review_links), max_reviews)}\")\n",
    "            \n",
    "            try:\n",
    "                review_data = self.extract_effect_sizes_from_page(link)\n",
    "                \n",
    "                # Add metadata to each effect size entry\n",
    "                for effect in review_data[\"effect_sizes\"]:\n",
    "                    effect[\"review_title\"] = review_data[\"title\"]\n",
    "                    effect[\"review_url\"] = review_data[\"url\"]\n",
    "                    effect[\"review_doi\"] = review_data[\"doi\"]\n",
    "                    effect[\"topic\"] = topic\n",
    "                    \n",
    "                all_effect_sizes.extend(review_data[\"effect_sizes\"])\n",
    "                \n",
    "                # Save intermediate results\n",
    "                self._save_intermediate_results(all_effect_sizes, topic, i+1)\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing {link}: {str(e)}\")\n",
    "                \n",
    "            # Be nice to the server\n",
    "            time.sleep(2)\n",
    "            \n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(all_effect_sizes)\n",
    "        \n",
    "        # Save final results\n",
    "        output_path = self.output_dir / f\"{topic}_effect_sizes.csv\"\n",
    "        df.to_csv(output_path, index=False)\n",
    "        logger.info(f\"Saved {len(df)} effect sizes to {output_path}\")\n",
    "        \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb7ed6b9-4321-401b-8399-ea86a44d1db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 13:58:20,895 - INFO - Searching Cochrane Library for: \"\" AND (\"meta-analysis\" OR \"effect size\" OR \"forest plot\")\n",
      "2025-03-25 13:58:29,829 - INFO - Found 0 reviews\n",
      "2025-03-25 13:58:29,832 - INFO - Saved 0 effect sizes to /Users/yiquntchen/Desktop/chen-lab/MEDAL/_effect_sizes.csv\n"
     ]
    }
   ],
   "source": [
    "extractor = CochraneEffectSizeExtractor(output_dir=\"/Users/yiquntchen/Desktop/chen-lab/MEDAL/\")\n",
    "df = extractor.extract_effect_sizes_for_topic(\"\", max_reviews=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43642d92-60e9-47cf-aecb-46926f883c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d986f02d-c03f-4eb5-9c4c-9ab35401de91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c88e903-8b85-4f4c-9d46-0d22ba663b97",
   "metadata": {},
   "outputs": [],
   "source": [
    " import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "BASE_URL = \"https://www.cochranelibrary.com\"\n",
    "SEARCH_URL = \"https://www.cochranelibrary.com/cdsr/reviews/topics\"\n",
    "HEADERS = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "def get_recent_reviews(years_back=10, max_pages=5):\n",
    "    review_links = []\n",
    "    for page in range(1, max_pages + 1):\n",
    "        url = f\"https://www.cochranelibrary.com/cdsr/reviews?page={page}\"\n",
    "        response = requests.get(url, headers=HEADERS)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        links = soup.find_all(\"a\", href=True)\n",
    "        for link in links:\n",
    "            href = link['href']\n",
    "            if href.startswith(\"/cdsr/doi/\") and \"full\" not in href:\n",
    "                full_link = BASE_URL + href + \"/full\"\n",
    "                review_links.append(full_link)\n",
    "\n",
    "        time.sleep(1)  # Be kind to the server\n",
    "\n",
    "    return list(set(review_links))\n",
    "\n",
    "def extract_sof_table(cochrane_url):\n",
    "    response = requests.get(cochrane_url, headers=HEADERS)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch {cochrane_url}\")\n",
    "        return None\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    sof_tables = soup.find_all(\"table\")\n",
    "    sof_data = []\n",
    "\n",
    "    for table in sof_tables:\n",
    "        if 'Summary of findings' in table.get_text():\n",
    "            rows = table.find_all(\"tr\")\n",
    "            for row in rows:\n",
    "                cols = row.find_all([\"td\", \"th\"])\n",
    "                cols = [c.get_text(strip=True) for c in cols]\n",
    "                if len(cols) > 1:\n",
    "                    sof_data.append(cols)\n",
    "\n",
    "    if sof_data:\n",
    "        return pd.DataFrame(sof_data)\n",
    "    return None\n",
    "\n",
    "def extract_themes(soup):\n",
    "    theme_tags = soup.find_all(\"a\", class_=\"taxonomy-link\")\n",
    "    themes = [tag.get_text(strip=True) for tag in theme_tags]\n",
    "    return themes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fe4aa43-805b-4dc0-9366-a56fd4404400",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = get_recent_reviews()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05d71070-1f42-45e6-a4d6-36886ae88812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = f\"https://www.cochranelibrary.com/cdsr/reviews?page={page}\"\n",
    "response = requests.get(url, headers=HEADERS)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1113709-644a-4515-8bc4-a51f0b43bc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Replace this with your actual Wiley TDM API token\n",
    "TDM_API_TOKEN = \"***WILEY_TDM_API_TOKEN_REDACTED***\"\n",
    "\n",
    "WILEY_HEADERS = {\n",
    "    \"apikey\": TDM_API_TOKEN,\n",
    "    \"Accept\": \"application/xml\"\n",
    "}\n",
    "\n",
    "CROSSREF_API = \"https://api.crossref.org/works\"\n",
    "\n",
    "\n",
    "def search_cochrane_reviews_crossref(rows=10):\n",
    "    query = \"cochrane systematic review\"\n",
    "    params = {\n",
    "        \"query\": query,\n",
    "        \"filter\": \"type:journal-article,container-title:Cochrane Database of Systematic Reviews\",\n",
    "        \"rows\": rows\n",
    "    }\n",
    "    response = requests.get(CROSSREF_API, params=params)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(\"Crossref search failed:\", response.status_code, response.text)\n",
    "        return []\n",
    "\n",
    "    items = response.json().get(\"message\", {}).get(\"items\", [])\n",
    "    dois = [item[\"DOI\"] for item in items if \"DOI\" in item]\n",
    "    return dois\n",
    "\n",
    "\n",
    "def get_fulltext_xml_by_doi(doi):\n",
    "    encoded_doi = urllib.parse.quote(doi)\n",
    "    meta_url = f\"https://api.wiley.com/onlinelibrary/tdm/v1/articles/{encoded_doi}/metadata\"\n",
    "    meta_response = requests.get(meta_url, headers=WILEY_HEADERS)\n",
    "\n",
    "    if meta_response.status_code != 200:\n",
    "        print(f\"Metadata not available for DOI: {doi}\")\n",
    "        return None\n",
    "\n",
    "    full_url = f\"https://api.wiley.com/onlinelibrary/tdm/v1/articles/{encoded_doi}/full\"\n",
    "    full_response = requests.get(full_url, headers=WILEY_HEADERS)\n",
    "\n",
    "    if full_response.status_code == 200:\n",
    "        return full_response.text\n",
    "    else:\n",
    "        print(f\"Failed to fetch fulltext for DOI: {doi} | Status: {full_response.status_code}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def parse_jats_for_key_info(xml_text):\n",
    "    root = ET.fromstring(xml_text)\n",
    "    ns = {'j': 'http://jats.nlm.nih.gov'}\n",
    "\n",
    "    title = root.findtext(\".//j:article-title\", default=\"\", namespaces=ns)\n",
    "    abstract = root.findtext(\".//j:abstract//j:p\", default=\"\", namespaces=ns)\n",
    "\n",
    "    sections = root.findall(\".//j:sec\", namespaces=ns)\n",
    "    section_texts = []\n",
    "    for sec in sections:\n",
    "        heading = sec.findtext(\"j:title\", default=\"\", namespaces=ns)\n",
    "        paras = [p.text for p in sec.findall(\"j:p\", namespaces=ns) if p.text]\n",
    "        section_texts.append({\"heading\": heading, \"content\": \" \".join(paras)})\n",
    "\n",
    "    return {\n",
    "        \"title\": title,\n",
    "        \"abstract\": abstract,\n",
    "        \"sections\": section_texts\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89aba045-52d8-4e7c-940b-adae63641e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search failed: 400 \n"
     ]
    }
   ],
   "source": [
    "articles = search_cochrane_reviews(rows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "474ff104-7488-4553-92c0-d69b2884b8fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59262e0f-3cfa-4d94-9079-f684f609734e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "\n",
    "for article in articles:\n",
    "    article_id = article.findtext(\"article-id\")\n",
    "    print(f\"Processing article ID: {article_id}\")\n",
    "\n",
    "    xml_text = get_fulltext_xml(article)\n",
    "    if xml_text:\n",
    "        parsed = parse_jats_for_key_info(xml_text)\n",
    "        parsed[\"article_id\"] = article_id\n",
    "        all_data.append(parsed)\n",
    "    else:\n",
    "        print(\"No XML fulltext available\")\n",
    "\n",
    "    time.sleep(1)  # Respectful delay\n",
    "\n",
    "pd.DataFrame(all_data).to_json(\"wiley_cochrane_reviews.json\", indent=2)\n",
    "print(\"Saved parsed data to wiley_cochrane_reviews.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ad63242-ba6b-49b8-b4f3-7518c347a539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "BASE_URL = \"https://www.cochranelibrary.com\"\n",
    "SEARCH_URL = \"https://www.cochranelibrary.com/cdsr/reviews\"\n",
    "\n",
    "def get_review_links(pages=1):\n",
    "    links = []\n",
    "    for page in range(1, pages + 1):\n",
    "        url = f\"{SEARCH_URL}?page={page}\"\n",
    "        response = requests.get(url)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to fetch page {page}\")\n",
    "            continue\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        for link in soup.select(\"a.search-result-title-link\"):\n",
    "            href = link.get(\"href\")\n",
    "            if href and \"/cdsr/\" in href:\n",
    "                links.append(BASE_URL + href)\n",
    "        time.sleep(1)\n",
    "    return links\n",
    "\n",
    "def extract_sof_table(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch: {url}\")\n",
    "        return []\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    sof_tables = soup.select(\"table.sof-table\")\n",
    "    all_rows = []\n",
    "\n",
    "    for table in sof_tables:\n",
    "        headers = [th.get_text(strip=True) for th in table.select(\"thead th\")]\n",
    "        for row in table.select(\"tbody tr\"):\n",
    "            cells = [td.get_text(strip=True) for td in row.select(\"td\")]\n",
    "            if len(cells) == len(headers):\n",
    "                all_rows.append(dict(zip(headers, cells)))\n",
    "    \n",
    "    return all_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "641cb7c9-62ed-4e20-ba7f-5bca2f1f76bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch page 1\n",
      "Failed to fetch page 2\n",
      "Found 0 reviews\n"
     ]
    }
   ],
   "source": [
    "\n",
    "review_links = get_review_links(pages=2)  # You can increase this\n",
    "print(f\"Found {len(review_links)} reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df327aa-2d72-437d-a043-2e7131a8c1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "all_data = []\n",
    "for url in review_links:\n",
    "    print(f\"Scraping: {url}\")\n",
    "    sof_data = extract_sof_table(url)\n",
    "    all_data.append({\n",
    "        \"url\": url,\n",
    "        \"sof_table\": sof_data\n",
    "    })\n",
    "    time.sleep(1)\n",
    "\n",
    "pd.DataFrame(all_data).to_json(\"cochrane_sof_tables.json\", indent=2)\n",
    "print(\"Saved extracted SoF tables to cochrane_sof_tables.json\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56997cca-b7ea-48db-ba66-ab32101181bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2a3557be-3e9e-4e6b-8cd3-6bc2bb59a6bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "900dc432-c584-43b8-b259-d78cb6bcd57d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2ddd34ce-07e2-450e-91e0-93addbbcf244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_cochrane_reviews(start_year, end_year, rows=20):\n",
    "    query = \"Cochrane Database of Systematic Reviews\"\n",
    "    filters = {\n",
    "        \"from-pub-date\": f\"{start_year}-01-01\",\n",
    "        \"until-pub-date\": f\"{end_year}-12-31\",\n",
    "        \"type\": \"journal-article\"\n",
    "    }\n",
    "    results = cr.works(query=query, filter=filters, limit=rows)\n",
    "    return results['message']['items']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f437b09-b629-4474-be1f-c1e2f515f1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_information(articles):\n",
    "    extracted_data = []\n",
    "    for article in articles:\n",
    "        doi = article.get('DOI', 'N/A')\n",
    "        title = article.get('title', ['N/A'])[0]\n",
    "        pub_date = article.get('published-print', {}).get('date-parts', [['N/A']])[0][0]\n",
    "        link = f\"https://doi.org/{doi}\"\n",
    "        extracted_data.append({\n",
    "            'DOI': doi,\n",
    "            'Title': title,\n",
    "            'Publication Year': pub_date,\n",
    "            'Link': link\n",
    "        })\n",
    "    return extracted_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5638ff4e-06af-4e8e-ae18-7dbfff7c67ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 23:43:57,515 - INFO - HTTP Request: GET https://api.crossref.org/works?query=Cochrane+Database+of+Systematic+Reviews&filter=from-pub-date%3A2015-01-01%2Cuntil-pub-date%3A2025-12-31%2Ctype%3Ajournal-article&rows=50 \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "start_year = 2015\n",
    "end_year = 2025\n",
    "num_articles = 50\n",
    "\n",
    "articles = search_cochrane_reviews(start_year, end_year, rows=num_articles)\n",
    "extracted_data = extract_information(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3da3cfc0-1def-41d9-9ae8-fa25c1314c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8c5f2068-17d4-48c5-bc06-0e581b909fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['indexed', 'reference-count', 'publisher', 'content-domain', 'DOI', 'type', 'created', 'update-policy', 'source', 'is-referenced-by-count', 'title', 'prefix', 'author', 'member', 'published-online', 'reference', 'updated-by', 'container-title', 'language', 'link', 'deposited', 'score', 'resource', 'editor', 'issued', 'references-count', 'URL', 'ISSN', 'issn-type', 'published'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ac47169b-461c-4383-8cfe-057cd290067c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10.1002/14651858.cd013268'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles[0]['DOI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3492ca40-685f-48f2-9bda-5b7743968e66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
