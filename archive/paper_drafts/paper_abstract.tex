We evaluated GPT-5 on PubMed-derived clinical questions requiring three-way judgments (Yes/No/No Evidence) and examined factors associated with task difficulty, including discipline, citation volume, publication year, and the provenance of contextual abstracts. On 8{,}530 items (8{,}366 unique questions), GPT-5 achieved exact-match accuracy of 0.678 with 100\% response success. Accuracy varied across disciplines, with higher performance in Tobacco, Drugs and Alcohol (0.746; $n=169$), Lungs and Airways (0.723; $n=382$), Pain and Anaesthesia (0.721; $n=337$), Infectious Disease (0.701; $n=405$), and Cancer (0.696; $n=621$), and lower performance in Complementary and Alternative Medicine (0.576; $n=92$) and Health and Safety at Work (0.521; $n=48$). Accuracy increased monotonically with citation count (e.g., 0.591 for [0--5), 0.617 for [5--12), 0.666 for [12--21), 0.721 for [21--39), and 0.791 for [39--1035)), and a logistic regression found that log(1+citations) was a significant predictor of correctness (odds ratio $1.34$, 95\% CI: $1.29$--$1.40$). In a 500-item subset originally answered incorrectly, accuracies by context condition were: None 0.164 ($n=500$), Correct abstract 0.790 ($n=500$), Random abstract 0.116 ($n=500$), and PubMed top-3 abstracts 0.150 ($n=20$, excluding the same DOI). These results highlight strong baseline performance, domain variability, and substantial gains from high-precision retrieval of the correct source abstract for evidence-based clinical QA.


